{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import pandas as pd, numpy as np \n",
    "\n",
    "# prefect  \n",
    "from prefect import Flow, task\n",
    "from prefect.engine.executors import DaskExecutor\n",
    "\n",
    "# NLP \n",
    "from sklearn.feature_extraction import text \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "# Dask \n",
    "from dask.distributed import Client\n",
    "from dask_saturn import SaturnCluster\n",
    "\n",
    "#misc files/text processing\n",
    "import pickle\n",
    "import re\n",
    "import collections\n",
    "import pprint\n",
    "import re\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install prefect \n",
    "# ! pip install bson\n",
    "# ! pip install jupyter_nbextensions_configurator\n",
    "# ! jupyter nbextensions_configurator enable --user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open('./data/twenty16_debate_corpus.pkl', 'rb') as f:\n",
    "       corpus = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Speaker': 'Woodruff',\n",
       " 'Text': 'Secretary Clinton, your campaign -- you and your campaign have made a clear appeal to women voters. You have talked repeatedly about the fact, we know you would be, if elected, the first woman president. But in New Hampshire 55 percent of the women voters supported and voted for Senator Sanders. What are women missing about you?',\n",
       " 'Date': '2/11/2016',\n",
       " 'Party': 'Democratic',\n",
       " 'Location': 'Milwaukee, Wisconsin',\n",
       " 'URL': 'http://www.presidency.ucsb.edu/ws/index.php?pid=111520',\n",
       " '_id': ObjectId('5dc1cc86619bc07aa810ddee')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = text.ENGLISH_STOP_WORDS.union(['im','dont','need','want','senator','governor','know',\n",
    "                                           'come','theyre','youre','going','think','said','thats',\n",
    "                                           'just','make','did','got','mr','ms','ive','audience'])\n",
    "\n",
    "# assign stop words \n",
    "common_debate_words = stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dict to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_df(rawtext):\n",
    "    '''transform dictionary of raw text to dataframe'''\n",
    "    text_df = pd.DataFrame.from_dict(rawtext)\n",
    "    text_df = text_df.drop(['URL', '_id'], axis = 1)\n",
    "    return text_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean text   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_round1(text):\n",
    "    '''make text lowercase, remove text in parantheses, remove punctuation and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\(.*?\\)', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    \n",
    "    text = re.sub('[‘’“”…]', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    return text\n",
    "\n",
    "round1 = lambda x: clean_text_round1(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=common_debate_words,min_df=10, max_df=8.5)\n",
    "def count_vectorize(series):\n",
    "    '''create document term matrix'''\n",
    "    doc_word = vectorizer.fit_transform(series)\n",
    "    return doc_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit LSA model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa = TruncatedSVD(10)\n",
    "def fit_model(doc_word):\n",
    "    '''fit topic model'''\n",
    "    doc_topic = lsa.fit_transform(doc_word)\n",
    "    return doc_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topics by word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_word(model):\n",
    "    '''create topic by word dataframe'''\n",
    "    topic_word_df = pd.DataFrame(model.components_.round(10),\n",
    "             index = [\"component_1\",\"component_2\",\"component_3\",\"component_4\",\"component_5\",\n",
    "                     \"component_6\", \"component_7\",\"component_8\",\"component_9\",\"component_10\"],\n",
    "             columns = vectorizer.get_feature_names())\n",
    "    return topic_word_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    '''print topics outputted from model to stdout'''\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Prefect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict to dataframe : step successful\n",
      "clean : step successful\n",
      "fit vectorizer : step successful\n",
      "fit lsa : step successful\n",
      "topic by words : step successful\n",
      "\n",
      "Topic  0\n",
      "people, country, president, america, say, right, american, states, years, government\n",
      "\n",
      "Topic  1\n",
      "president, states, united, clinton, obama, isis, world, secretary, america, iran\n",
      "\n",
      "Topic  2\n",
      "tax, percent, jobs, taxes, government, plan, pay, money, economy, cut\n",
      "\n",
      "Topic  3\n",
      "country, america, president, jobs, world, tax, united, states, trade, percent\n",
      "\n",
      "Topic  4\n",
      "president, tax, people, states, united, isis, obama, taxes, war, plan\n",
      "\n",
      "Topic  5\n",
      "president, care, health, government, insurance, clinton, states, act, federal, affordable\n",
      "\n",
      "Topic  6\n",
      "government, care, health, federal, states, years, weve, things, big, deal\n",
      "\n",
      "Topic  7\n",
      "care, health, isis, states, world, insurance, united, tax, war, affordable\n",
      "\n",
      "Topic  8\n",
      "government, states, clinton, united, america, world, secretary, hillary, economy, american\n",
      "\n",
      "Topic  9\n",
      "government, president, clinton, country, obama, isis, secretary, hillary, wall, street\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "# topic model preprocessing pipeline\n",
    "\n",
    "# dict to dataframe\n",
    "corpus_df = dict_to_df(corpus)\n",
    "print('dict to dataframe : step successful')\n",
    "\n",
    "# clean text \n",
    "corpus_df['Text'] = pd.DataFrame(corpus_df['Text'].apply(round1))\n",
    "print('clean : step successful')\n",
    "\n",
    "# fit vectorizer \n",
    "doc_w = count_vectorize(corpus_df['Text'])\n",
    "print('fit vectorizer : step successful')\n",
    "\n",
    "# fit LSA model \n",
    "lsa_model = fit_model(doc_w)\n",
    "print('fit lsa : step successful')\n",
    "\n",
    "# topics by words matrix \n",
    "topic_word_mtx = topic_word(lsa)\n",
    "print('topic by words : step successful')\n",
    "\n",
    "# display topics \n",
    "display_topics(lsa, vectorizer.get_feature_names(), 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Not bad--the LSA model ran and we have some topics, but what if we want this model to rerun on new data at a certain time in the future? First we'd need to make our function for loading data into function, but additionally, there's no real way to do this from within our notebook. This is where Prefect comes in**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authenticate Prefect Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Authenticate]('https://docs.prefect.io/orchestration/tutorial/configure.html#authenticating-with-prefect-cloudyour') your local machine to leverage Prefect Cloud. \n",
    "\n",
    "1. Sign up for the free tier of Prefect Cloud \n",
    "2. Open menu (three lines top right of dashboard page) \n",
    "3. Click API tokens \n",
    "4. Create 1 token for the tenant (save it somewhere on your computer) \n",
    "5. Create anoter token for the runner (save it somewhere on your computer) \n",
    "6. From the dashboard select new project and create a new project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Login to Prefect: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mLogin successful!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! prefect auth login -t eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJ0ZW5hbnRfaWQiOiI5N2FmZTgyMC02MTFlLTRmMDEtYjEzOC0zNDhkYjAwZWY1MjQiLCJ1c2VyX2lkIjoiMDhlODgyOTctNDI5MS00Yjc0LWFjNWYtOTA1ODZlY2RiZGRiIiwiYXBpX3Rva2VuX3Njb3BlIjoiVEVOQU5UIiwiaWF0IjoxNTg5MzExMDUwLCJleHAiOjQxMDI0NDQ4MDAsImp0aSI6ImM0MjliMjZmLTdjNTQtNDFmZi1hZDEzLTJmMjdmOGM2MmU1OCIsImlzcyI6IlByZWZlY3QgQ2xvdWQiLCJhdWQiOiJQcmVmZWN0IENsb3VkIEFQSSIsInR5cCI6IkFQSSJ9.KeZY-ztg9alOlY4ZzXVQYAeDdkYYpPEwhUccfIdBSNWG_6XGhr6Nh9oKCyllu0jC3bEYB3qmEu7FLXxcEDdqsRLt91jrWGGl4ULyEPsjfRQfFdU8OQE0Z8AfFmsGMWKFpZ-Ce8Wo6_yO1ERkQHv2-Rh34L6-JKJyQj0JP-QB5kl3Cr435T0kwu65vRzVS-PdDwN698hNnf_alMD7RrOTWV0ZNbl-qnPB9hI2ZG4e2232ejyZh97fa6jNHTxlw3uxAiJSuaH1YIiRE8_AbSL436KFkqOzNMTC7jxHVip_TH09r9Eirau0GpUnKoMOe9Km62Zan4zYg8SqHUSqscs81Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can store the runner token as environment variable, or paste it into the run_agent command at the bottom of the flow block in the code below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! export PREFECT__CLOUD__AGENT__AUTH_TOKEN=<COPIED_RUNNER_TOKEN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Prefect Flow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if you run our NLP flow below, it will be registered with the prefect API (through the ```.register``` command). Now we can use an agent to watch for flow runs that are scheduled by the Prefect API and execute them accordingly. \n",
    "\n",
    "Uncomment the ```.run_agent``` line after the register command to start a Local Agent. Note -- the Local Agent will use the RUNNER token stored in your environment but if you want to manually pass it a token you may do so with ```run_agent(token=<YOUR_RUNNER_TOKEN>)```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "people, country, president, america, say, right, american, states, years, government\n",
      "\n",
      "Topic  1\n",
      "president, states, united, clinton, obama, isis, world, secretary, america, iran\n",
      "\n",
      "Topic  2\n",
      "tax, percent, jobs, taxes, government, plan, money, pay, economy, cut\n",
      "\n",
      "Topic  3\n",
      "country, america, president, jobs, world, tax, united, states, trade, percent\n",
      "\n",
      "Topic  4\n",
      "president, tax, people, states, united, isis, obama, taxes, plan, war\n",
      "\n",
      "Topic  5\n",
      "president, care, health, government, insurance, clinton, state, federal, money, obama\n",
      "\n",
      "Topic  6\n",
      "government, care, health, states, united, federal, years, deal, things, way\n",
      "\n",
      "Topic  7\n",
      "care, health, states, isis, tax, united, insurance, world, secretary, clinton\n",
      "\n",
      "Topic  8\n",
      "states, united, government, america, clinton, world, secretary, hillary, new, economy\n",
      "\n",
      "Topic  9\n",
      "government, clinton, wall, street, country, secretary, president, big, obama, isis\n",
      "[2020-05-12 20:49:20] INFO - prefect.FlowRunner | Beginning Flow run for 'NLP : Debate Transcripts'\n",
      "[2020-05-12 20:49:20] INFO - prefect.FlowRunner | Starting flow run.\n",
      "[2020-05-12 20:49:20] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n",
      "Result Handler check: OK\n",
      "Flow: https://cloud.prefect.io/sami-saturncloud-io/flow/8bc3760c-dc0d-4b52-a8e8-ebcbb2fb8811\n",
      "\n",
      " ____            __           _        _                    _\n",
      "|  _ \\ _ __ ___ / _| ___  ___| |_     / \\   __ _  ___ _ __ | |_\n",
      "| |_) | '__/ _ \\ |_ / _ \\/ __| __|   / _ \\ / _` |/ _ \\ '_ \\| __|\n",
      "|  __/| | |  __/  _|  __/ (__| |_   / ___ \\ (_| |  __/ | | | |_\n",
      "|_|   |_|  \\___|_|  \\___|\\___|\\__| /_/   \\_\\__, |\\___|_| |_|\\__|\n",
      "                                           |___/\n",
      "\n",
      "[2020-05-12 20:49:21,404] INFO - agent | Starting LocalAgent with labels ['jupyter-sami-2denergy', 'azure-flow-storage', 'gcs-flow-storage', 's3-flow-storage']\n",
      "[2020-05-12 20:49:21,405] INFO - agent | Agent documentation can be found at https://docs.prefect.io/orchestration/\n",
      "[2020-05-12 20:49:21,405] INFO - agent | Agent connecting to the Prefect API at https://api.prefect.io\n",
      "[2020-05-12 20:49:21,453] INFO - agent | Waiting for flow runs...\n",
      "[2020-05-12 21:13:22,692] INFO - agent | Keyboard Interrupt received: Agent is shutting down.\n"
     ]
    }
   ],
   "source": [
    "with Flow(\"NLP : Debate Transcripts\") as nlp_flow:\n",
    "    \n",
    "# topic model preprocessing pipeline\n",
    "\n",
    "    # dict to dataframe\n",
    "    corpus_df = dict_to_df(corpus)\n",
    "\n",
    "    # clean text \n",
    "    corpus_df['Text'] = pd.DataFrame(corpus_df['Text'].apply(round1))\n",
    "\n",
    "    # fit vectorizer \n",
    "    doc_w = count_vectorize(corpus_df['Text'])\n",
    "\n",
    "    # fit LSA model \n",
    "    lsa_model = fit_model(doc_w)\n",
    "\n",
    "    # topics by words matrix \n",
    "    topic_word_mtx = topic_word(lsa)\n",
    "\n",
    "    # display topics \n",
    "    display_topics(lsa, vectorizer.get_feature_names(), 10)\n",
    "\n",
    "nlp_flow.run()\n",
    "nlp_flow.register(project_name='nlp_demo')\n",
    "nlp_flow.run_agent('eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJ0ZW5hbnRfaWQiOiI5N2FmZTgyMC02MTFlLTRmMDEtYjEzOC0zNDhkYjAwZWY1MjQiLCJ1c2VyX2lkIjpudWxsLCJhcGlfdG9rZW5fc2NvcGUiOiJSVU5ORVIiLCJyb2xlIjoiUlVOTkVSIiwiaWF0IjoxNTg5MzExNzQ2LCJleHAiOjQxMDI0NDQ4MDAsImp0aSI6ImRkYzBmY2JkLTAzN2ItNGUzZS05MTk1LWNlYmQ4ODNhYjQyNiIsImlzcyI6IlByZWZlY3QgQ2xvdWQiLCJhdWQiOiJQcmVmZWN0IENsb3VkIEFQSSIsInR5cCI6IkFQSSJ9.FeoGCZ_tKtM81u3pzP6YjjIVz1VrUsxLptpPx1wUpishylu2oEe7neZb90iuldRODMo-glFzS2gc55f8gNfdLiShD8ESd3ahxqjvjL2JCy-UtwCexskKs1k0jPTKxvyuGRVGqVTe3tecZQk97jRDKEiI6PtH8Tg9U7MqjdJM_YSPskril1qlOihbRRM-na2blPr4hR8ppu3HZtUw4bPCt-k1ZvEhh9tWLcSMKWLSE-q1X74mrPOMZ8iydbn3gT9h3V9NVznSLNplWqrKdv9bkfn52yt5XFhZozwHtDw3piQ2k-OQtmu_zuQXV84g7lcwYuRDMmeC8QIHWFfVxnHLyg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What just happened? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You might notice your cell is still running (*), You can interrupt your kernel to stop the agent from continually querying. \n",
    "The agent should by default stop querying after a minute (check your dashboard to make sure, you can just remove the agent from your dashboard after that).**\n",
    "\n",
    "**With extremely minimal code changes we now have a prefect flow setup which allows us to do really powerful things like execute this entire flow with a click of a button from the prefect UI, or schedule runs for a specific time of day, below is how you schedule this run from the notebook directly** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! prefect run cloud --name 'NLP : Debate Transcripts' --project 'nlp_demo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prefect flow on Saturn Dask cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what if theoretically, we have a much larger corpus that cannot be fit into memory -- we can run the flow on a dask cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Saturn Dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012c8e304fea4f37a3da4e725dfce522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>SaturnCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster = SaturnCluster()\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'running'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then simply point the prefec dask executor to url of saturn dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-05-12 16:52:31] INFO - prefect.FlowRunner | Beginning Flow run for 'NLP : Debate Transcripts'\n",
      "[2020-05-12 16:52:31] INFO - prefect.FlowRunner | Starting flow run.\n",
      "[2020-05-12 16:52:31] INFO - prefect.FlowRunner | Flow run SUCCESS: all reference tasks succeeded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Success: \"All reference tasks succeeded.\">"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executor = DaskExecutor('tcp://sami-energy-dask.main-namespace:8786')\n",
    "nlp_flow.run(executor=executor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
